{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This notebook was put together by [Jake Vanderplas](http://www.vanderplas.com) for PyCon 2015. Source and license info is on [GitHub](https://github.com/jakevdp/sklearn_pycon2015/).</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Estimation: Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll explore **Gaussian Mixture Models**, which is an unsupervised clustering & density estimation technique.\n",
    "\n",
    "We'll start with our standard set of initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Gaussian Mixture Models\n",
    "\n",
    "We previously saw an example of K-Means, which is a clustering algorithm which is most often fit using an expectation-maximization approach.\n",
    "\n",
    "Here we'll consider an extension to this which is suitable for both **clustering** and **density estimation**.\n",
    "\n",
    "For example, imagine we have some one-dimensional data in a particular distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAFVCAYAAADPM8ekAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a93f6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "x = np.concatenate([np.random.normal(0, 2, 2000),\n",
    "                    np.random.normal(5, 5, 2000),\n",
    "                    np.random.normal(3, 0.5, 600)])\n",
    "plt.hist(x, 80, normed=True)\n",
    "plt.xlim(-10, 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian mixture models will allow us to approximate this density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GMM estimation with 4 components, but got only 1 samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-99b0908e5369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jslice/anaconda/lib/python2.7/site-packages/sklearn/mixture/gmm.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    433\u001b[0m             raise ValueError(\n\u001b[1;32m    434\u001b[0m                 \u001b[0;34m'GMM estimation with %s components, but got only %s samples'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 (self.n_components, X.shape[0]))\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mmax_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GMM estimation with 4 components, but got only 1 samples"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GMM\n",
    "clf = GMM(4, n_iter=500, random_state=3).fit(x)\n",
    "xpdf = np.linspace(-10, 20, 1000)\n",
    "density = np.exp(clf.score(xpdf))\n",
    "\n",
    "plt.hist(x, 80, normed=True, alpha=0.5)\n",
    "plt.plot(xpdf, density, '-r')\n",
    "plt.xlim(-10, 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this density is fit using a **mixture of Gaussians**, which we can examine by looking at the ``means_``, ``covars_``, and ``weights_`` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.covars_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(x, 80, normed=True, alpha=0.3)\n",
    "plt.plot(xpdf, density, '-r')\n",
    "\n",
    "for i in range(clf.n_components):\n",
    "    pdf = clf.weights_[i] * stats.norm(clf.means_[i, 0],\n",
    "                                       np.sqrt(clf.covars_[i, 0])).pdf(xpdf)\n",
    "    plt.fill(xpdf, pdf, facecolor='gray',\n",
    "             edgecolor='none', alpha=0.3)\n",
    "plt.xlim(-10, 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These individual Gaussian distributions are fit using an expectation-maximization method, much as in K means, except that rather than explicit cluster assignment, the **posterior probability** is used to compute the weighted mean and covariance.\n",
    "Somewhat surprisingly, this algorithm **provably** converges to the optimum (though the optimum is not necessarily global)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many Gaussians?\n",
    "\n",
    "Given a model, we can use one of several means to evaluate how well it fits the data.\n",
    "For example, there is the Aikaki Information Criterion (AIC) and the Bayesian Information Criterion (BIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf.bic(x))\n",
    "print(clf.aic(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at these as a function of the number of gaussians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators = np.arange(1, 10)\n",
    "clfs = [GMM(n, n_iter=1000).fit(x) for n in n_estimators]\n",
    "bics = [clf.bic(x) for clf in clfs]\n",
    "aics = [clf.aic(x) for clf in clfs]\n",
    "\n",
    "plt.plot(n_estimators, bics, label='BIC')\n",
    "plt.plot(n_estimators, aics, label='AIC')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that for both the AIC and BIC, 4 components is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: GMM For Outlier Detection\n",
    "\n",
    "GMM is what's known as a **Generative Model**: it's a probabilistic model from which a dataset can be generated.\n",
    "One thing that generative models can be useful for is **outlier detection**: we can simply evaluate the likelihood of each point under the generative model; the points with a suitably low likelihood (where \"suitable\" is up to your own bias/variance preference) can be labeld outliers.\n",
    "\n",
    "Let's take a look at this by defining a new dataset with some outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Add 20 outliers\n",
    "true_outliers = np.sort(np.random.randint(0, len(x), 20))\n",
    "y = x.copy()\n",
    "y[true_outliers] += 50 * np.random.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GMM(4, n_iter=500, random_state=0).fit(y)\n",
    "xpdf = np.linspace(-10, 20, 1000)\n",
    "density_noise = np.exp(clf.score(xpdf))\n",
    "\n",
    "plt.hist(y, 80, normed=True, alpha=0.5)\n",
    "plt.plot(xpdf, density_noise, '-r')\n",
    "#plt.xlim(-10, 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the log-likelihood of each point under the model, and plot these as a function of ``y``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_likelihood = clf.score_samples(y)[0]\n",
    "plt.plot(y, log_likelihood, '.k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "detected_outliers = np.where(log_likelihood < -9)[0]\n",
    "\n",
    "print(\"true outliers:\")\n",
    "print(true_outliers)\n",
    "print(\"\\ndetected outliers:\")\n",
    "print(detected_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm misses a few of these points, which is to be expected (some of the \"outliers\" actually land in the middle of the distribution!)\n",
    "\n",
    "Here are the outliers that were missed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(true_outliers) - set(detected_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the non-outliers which were spuriously labeled outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(detected_outliers) - set(true_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should note that although all of the above is done in one dimension, GMM does generalize to multiple dimensions, as we'll see in the breakout session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Density Estimators\n",
    "\n",
    "The other main density estimator that you might find useful is *Kernel Density Estimation*, which is available via ``sklearn.neighbors.KernelDensity``. In some ways, this can be thought of as a generalization of GMM where there is a gaussian placed at the location of *every* training point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "kde = KernelDensity(0.15).fit(x[:, None])\n",
    "density_kde = np.exp(kde.score_samples(xpdf[:, None]))\n",
    "\n",
    "plt.hist(x, 80, normed=True, alpha=0.5)\n",
    "plt.plot(xpdf, density, '-b', label='GMM')\n",
    "plt.plot(xpdf, density_kde, '-r', label='KDE')\n",
    "plt.xlim(-10, 20)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these density estimators can be viewed as **Generative models** of the data: that is, that is, the model tells us how more data can be created which fits the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
